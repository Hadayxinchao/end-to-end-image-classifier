# End-to-End Image Classifier with MLOps

A complete MLOps pipeline for image classification demonstrating best practices in ML engineering.

## ğŸ¯ Project Overview

This project implements a full MLOps workflow for image classification, covering:
- âœ… Standardized project structure
- âœ… Configuration management with Hydra
- âœ… Data versioning with DVC
- âœ… **Experiment tracking with MLflow and W&B**
- âœ… **Pre-commit hooks & Auto-formatting**
- âœ… **Security scanning with Bandit**
- âœ… **Dependency vulnerability checking**
- âœ… **Docker optimization (multi-stage)**
- âœ… **Kubernetes deployment (production-ready)**
- âœ… **Weights & Biases tracking**
- âœ… Unit testing with pytest
- âœ… CI/CD with GitHub Actions
- âœ… Docker containerization
- âœ… Documentation with MkDocs

## ğŸš€ Quick Start

```bash
# 1. Clone repository
git clone https://github.com/Hadayxinchao/end-to-end-image-classifier.git
cd end-to-end-image-classifier

# 2. Install dependencies
pip install -r requirements.txt
pip install -e .

# 3. Setup pre-commit hooks
make setup-precommit

# 4. Setup W&B
make wandb-setup

# 5. Start training with W&B tracking
make train-wandb
```

## ğŸ“š Documentation

- **[MLOPS_AUTOMATION_GUIDE.md](MLOPS_AUTOMATION_GUIDE.md)** - Comprehensive automation guide
- **[GETTING_STARTED.md](GETTING_STARTED.md)** - Complete setup instructions
- **[DOCKER.md](DOCKER.md)** - Docker usage guide
- **[DVC_SETUP.md](DVC_SETUP.md)** - Data versioning setup
- **[EXPERIMENT_TRACKING.md](EXPERIMENT_TRACKING.md)** - Experiment tracking guide
- **[Online Documentation](https://hadayxinchao.github.io/end-to-end-image-classifier/)** - Full MkDocs documentation

## ğŸ“ Project Structure

```
end-to-end-image-classifier/
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/          # GitHub Actions workflows
â”‚       â”œâ”€â”€ tests.yaml      # CI pipeline
â”‚       â””â”€â”€ cml.yaml        # CML pipeline
â”‚
â”œâ”€â”€ configs/                # Hydra configuration files
â”‚   â”œâ”€â”€ config.yaml         # Main config
â”‚   â”œâ”€â”€ model/              # Model configs
â”‚   â”œâ”€â”€ data/               # Data configs
â”‚   â””â”€â”€ hyperparameters/    # Training hyperparameters
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # Original immutable data
â”‚   â”œâ”€â”€ processed/          # Processed data
â”‚   â””â”€â”€ .gitkeep
â”‚
â”œâ”€â”€ docs/                   # MkDocs documentation
â”‚   â”œâ”€â”€ index.md
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ models/                 # Trained models
â”‚   â””â”€â”€ .gitkeep
â”‚
â”œâ”€â”€ notebooks/              # Jupyter notebooks for exploration
â”‚   â””â”€â”€ exploratory/
â”‚
â”œâ”€â”€ reports/                # Generated reports and figures
â”‚   â””â”€â”€ figures/
â”‚
â”œâ”€â”€ src/                    # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data/               # Data loading and processing
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ make_dataset.py
â”‚   â”œâ”€â”€ models/             # Model architectures
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ model.py
â”‚   â”‚   â””â”€â”€ predict.py
â”‚   â”œâ”€â”€ training/           # Training scripts
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ train.py
â”‚   â””â”€â”€ utils/              # Utility functions
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ metrics.py
â”‚
â”œâ”€â”€ tests/                  # Unit tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_data.py
â”‚   â”œâ”€â”€ test_model.py
â”‚   â””â”€â”€ test_training.py
â”‚
â”œâ”€â”€ .dvcignore
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”œâ”€â”€ mkdocs.yml
â””â”€â”€ README.md
```

## ğŸš€ Getting Started

### Prerequisites

- Python 3.8+
- Git
- Docker (optional)

### Installation

1. Clone the repository:
```bash
git clone git@github.com:Hadayxinchao/end-to-end-image-classifier.git
cd end-to-end-image-classifier
```

2. Create virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Initialize DVC:
```bash
dvc init
```

### Usage

#### Training

```bash
# Train with default config
python src/training/train.py

# Train with experiment tracking (MLflow)
python src/training/train.py tracking=mlflow

# Train with Weights & Biases
python src/training/train.py tracking=wandb

# Override parameters
python src/training/train.py hyperparameters.learning_rate=0.001 hyperparameters.batch_size=64

# Use different config
python src/training/train.py model=resnet data=mnist
```

#### Experiment Tracking

```bash
# Setup experiment tracking
./scripts/setup_tracking.sh

# View MLflow UI
mlflow ui

# Compare experiments
python scripts/compare_experiments.py --experiment image_classifier

# Run hyperparameter sweep (W&B)
python scripts/wandb_sweep.py
```

See [EXPERIMENT_TRACKING.md](EXPERIMENT_TRACKING.md) for detailed usage.

#### Testing

```bash
# Run all tests
pytest tests/

# Run specific test
pytest tests/test_model.py -v

# Run with coverage
pytest --cov=src tests/
```

#### Inference

```bash
python src/models/predict.py --model_path models/best_model.pth --image_path data/test/image.jpg
```

## ğŸ³ Docker

Build and run the Docker container:

```bash
# Build image
docker build -t image-classifier:latest .

# Run container
docker run -p 8000:8000 image-classifier:latest
```

## ğŸ“Š DVC - Data Version Control

```bash
# Track data
dvc add data/raw/

# Push to remote storage
dvc push

# Pull data
dvc pull
```

## ğŸ§ª Testing

The project includes comprehensive unit tests:
- Data loading and preprocessing
- Model architecture and output shapes
- Loss function behavior
- Training utilities

## ğŸ“ˆ Continuous ML (CML)

CML automatically generates reports on each pull request:
- Training metrics
- Confusion matrix
- Classification report
- Model performance comparison

## ğŸ“š Documentation

Documentation is built with MkDocs:

```bash
# Serve locally
mkdocs serve

# Build static site
mkdocs build

# Deploy to GitHub Pages
mkdocs gh-deploy
```

## ğŸ”§ Configuration Management

Hydra manages all configurations in `configs/` directory. You can:
- Override any parameter from command line
- Create experiment configs
- Use config composition

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Run tests: `pytest tests/`
5. Submit a pull request

## ğŸ“ License

MIT License

## ğŸ‘¤ Author

Bui Ha - MLOps Course Project

## ğŸ™ Acknowledgments

- Cookiecutter Data Science template
- MLOps best practices from industry
